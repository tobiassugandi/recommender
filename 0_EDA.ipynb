{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidates / Items : Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_df = pl.read_csv(\"data/Books.csv\", infer_schema_length=10000)\n",
    "books_df = pl.read_csv(\"data/Books.csv\", schema_overrides={\"Year-Of-Publication\": pl.Utf8})\n",
    "print(f\"{len(books_df)=} rows\")\n",
    "print(books_df.head(2))\n",
    "# print(books_df.describe())\n",
    "# 280k rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Books data\n",
    "def pubYear_to_numeric(df):\n",
    "    \n",
    "    # Convert publication year to numeric, setting invalid values to null\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"Year-Of-Publication\").cast(pl.Float32, strict=False)\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_books_df = pubYear_to_numeric(books_df)\n",
    "# print(cleaned_books_df.head(1))\n",
    "# print(cleaned_books_df.describe())\n",
    "print(\"books_df null count\")\n",
    "print(books_df.null_count())\n",
    "print(\"cleaned_books_df null count\")\n",
    "print(cleaned_books_df.null_count())\n",
    "\n",
    "\n",
    "print(f\"{len(cleaned_books_df)=} rows\")\n",
    "print(f\"after dropping nulls,\")\n",
    "cleaned_books_df = cleaned_books_df.drop_nulls()\n",
    "print(f\"  {len(cleaned_books_df)=} rows\")\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print unique \n",
    "print(f\"{cleaned_books_df.select('ISBN').n_unique()=}\")   \n",
    "print(f\"{cleaned_books_df.select('Publisher').n_unique()=}\")     \n",
    "print(f\"{cleaned_books_df.select('Book-Author').n_unique()=}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_books_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Show books with missing publication year\n",
    "print(\"Show books with missing Book-Author\")\n",
    "print(cleaned_books_df.filter(pl.col(\"Book-Author\").is_null()))\n",
    "\n",
    "# # Show books with missing author\n",
    "print(\"Show books with missing Publisher\")\n",
    "print(cleaned_books_df.filter(pl.col(\"Publisher\").is_null()))\n",
    "\n",
    "# show books with missing publisher\n",
    "print(\"Show books with missing publication year\")\n",
    "cleaned_books_df.filter(pl.col(\"Year-Of-Publication\").is_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_books_df = cleaned_books_df.filter(\n",
    "    # (pl.col(\"Year-Of-Publication\").is_not_null()) &  # Keep non-null values\n",
    "    (pl.col(\"Year-Of-Publication\") >= 1940) &  # to make normalization easier\n",
    "    (pl.col(\"Year-Of-Publication\") <= 2025)    # Before or in the near future\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_books_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze distribution of book ages\n",
    "plt.figure(figsize=(10, 6))\n",
    "cleaned_books_df.select(\"Year-Of-Publication\").to_pandas().hist(bins=50)\n",
    "plt.title(\"Distribution of Year-Of-Publication\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Books data\n",
    "def clean_books_data(df):\n",
    "\n",
    "    \n",
    "    # Convert publication year to numeric, setting invalid values to null\n",
    "    df = pubYear_to_numeric(df)\n",
    "    \n",
    "    # drop nulls\n",
    "    df = df.drop_nulls()\n",
    "\n",
    "    df = df.filter(\n",
    "        (pl.col(\"Year-Of-Publication\") >= 1940) &  # to make normalization easier\n",
    "        (pl.col(\"Year-Of-Publication\") <= 2025)    # Before or in the near future\n",
    "    )\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop([\"Image-URL-S\", \"Image-URL-M\"])\n",
    "    # rename to lowercase with underscore\n",
    "    df = df.rename({\"Book-Title\": \"book_title\", \n",
    "                    \"Book-Author\": \"book_author\", \n",
    "                    \"Year-Of-Publication\": \"year_of_publication\", \n",
    "                    \"Publisher\": \"publisher\",\n",
    "                    \"ISBN\": \"isbn\",\n",
    "                    \"Image-URL-L\": \"image_url_l\",})\n",
    "\n",
    "\n",
    "    # # Fill missing values\n",
    "    # df = df.with_columns([\n",
    "    #     pl.col(\"Book-Title\").fill_null(\"Unknown Title\"),\n",
    "    #     pl.col(\"Book-Author\").fill_null(\"Unknown Author\"),\n",
    "    #     pl.col(\"Publisher\").fill_null(\"Unknown Publisher\"),\n",
    "    #     pl.col(\"Year-Of-Publication\").fill_null(-1)\n",
    "    #     # For numerical year, use median for missing values\n",
    "    #     # pl.col(\"Year-Of-Publication\").fill_null(\n",
    "    #     #     df.select(pl.col(\"Year-Of-Publication\"))\n",
    "    #     #     .filter(pl.col(\"Year-Of-Publication\").is_not_null())\n",
    "    #     #     .select(pl.col(\"Year-Of-Publication\").median()).item()\n",
    "    #     # )\n",
    "    # ])\n",
    "    \n",
    "    # # Extract year features (like book age)\n",
    "    # current_year = datetime.now().year\n",
    "    # df = df.with_columns([\n",
    "    #     (current_year - pl.col(\"Year-Of-Publication\")).alias(\"Book-age\")\n",
    "    # ])\n",
    "    \n",
    "    # # Limit extremely long titles and author names for better processing\n",
    "    # df = df.with_columns([\n",
    "    #     pl.col(\"Book-Title\").str.slice(0, 100).alias(\"Book-Title\"),\n",
    "    #     pl.col(\"Book-Author\").str.slice(0, 100).alias(\"Book-Author\")\n",
    "    # ])\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books_df = clean_books_data(books_df)\n",
    "print(clean_books_df.head(2))\n",
    "print(clean_books_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nans\n",
    "pd_df = clean_books_df.to_pandas()\n",
    "pd_df[\"year_of_publication\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pl.read_csv(\"data/users.csv\")\n",
    "print(users_df.head())\n",
    "print(users_df.describe())\n",
    "# 280k rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Users data\n",
    "def clean_users_data(df):\n",
    "    df = df.rename({\"User-ID\": \"user_id\", \"Location\": \"location\", \"Age\": \"age\"})\n",
    "\n",
    "    # # Split the location safely\n",
    "    # df = df.with_columns([\n",
    "    #     pl.col(\"Location\").fill_null(\"\").str.split(\",\").alias(\"Location_Split\")\n",
    "    # ])\n",
    "\n",
    "    # # Filter out rows where the location does not have exactly 3 parts\n",
    "    # df = df.filter(pl.col(\"Location_Split\").list.len() != 3)\n",
    "    # print(df.head(3))\n",
    "\n",
    "    # # Safely split location (    # Split the location safely\n",
    "    # df = df.with_columns([\n",
    "    #     pl.col(\"Location\").str.split(\",\").alias(\"Location_Split\")\n",
    "    # ]).with_columns([\n",
    "    #     pl.col(\"Location_Split\").list.get(0, default=\"Unknown\").alias(\"City\"),\n",
    "    #     pl.col(\"Location_Split\").list.get(1, default=\"Unknown\").alias(\"State\"),\n",
    "    #     pl.col(\"Location_Split\").list.get(2, default=\"Unknown\").alias(\"Country\"),\n",
    "    # ]).drop(\"Location_Split\")  # Drop the temporary split columnrop the temporary split column\n",
    "    \n",
    "    # Filter out unreasonable ages (e.g., too young or too old)\n",
    "    df = df.with_columns([\n",
    "        pl.when((pl.col(\"age\") < 5) | (pl.col(\"age\") > 100))\n",
    "        .then(pl.lit(None))\n",
    "        .otherwise(pl.col(\"age\"))\n",
    "        .alias(\"age\")\n",
    "    ])\n",
    "\n",
    "    median_age = df[\"age\"].median()\n",
    "    print(f'{median_age=}')\n",
    "\n",
    "\n",
    "    # Fill missing ages with the median age\n",
    "    np.random.seed(42) # Set random seed for reproducibility\n",
    "    df = df.with_columns([\n",
    "        pl.when(pl.col(\"age\").is_null())\n",
    "        .then(df[\"age\"].median() + np.random.normal(0, 5, size=df.shape[0]))\n",
    "        .otherwise(pl.col(\"age\"))\n",
    "        .alias(\"age\")\n",
    "    ])\n",
    "\n",
    "    # # Create age buckets for better feature representation\n",
    "    # df = df.with_columns([\n",
    "    #     pl.when(pl.col(\"age\") == -1).then(\"Unknown\")\n",
    "    #     .when(pl.col(\"age\") < 18).then(\"Under 18\")\n",
    "    #     .when(pl.col(\"age\") < 25).then(\"18-24\")\n",
    "    #     .when(pl.col(\"age\") < 35).then(\"25-34\")\n",
    "    #     .when(pl.col(\"age\") < 45).then(\"35-44\")\n",
    "    #     .when(pl.col(\"age\") < 55).then(\"45-54\")\n",
    "    #     .when(pl.col(\"age\") < 65).then(\"55-64\")\n",
    "    #     .otherwise(\"65+\")\n",
    "    #     .alias(\"age-Bucket\")\n",
    "    # ])\n",
    "   \n",
    "    # convert user_id from int to string\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"user_id\").cast(pl.Utf8),\n",
    "        pl.col(\"age\").cast(pl.Float32)\n",
    "    ])\n",
    " \n",
    "    return df\n",
    "\n",
    "cleaned_users_df = clean_users_data(users_df)\n",
    "print(cleaned_users_df.head(3))\n",
    "print(cleaned_users_df.describe())\n",
    "print(f\"n unique User-ID: {cleaned_users_df.select('user_id').n_unique()}\")\n",
    "print(f\"n unique Location: {cleaned_users_df.select('location').n_unique()}\")\n",
    "\n",
    "\n",
    "# # Analyze age bucket distribution\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# age_counts = cleaned_users_df.group_by(\"age-Bucket\").count().sort(\"count\", descending=True)\n",
    "# sns.barplot(x=age_counts[\"age-Bucket\"].to_pandas(), y=age_counts[\"count\"].to_pandas())\n",
    "# plt.title(\"User Count by age Bucket\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze age distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "cleaned_users_df.filter(pl.col(\"age\") > -2).select(\"age\").to_pandas().hist(bins=20)\n",
    "plt.title(\"Distribution of User ages\")\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transactions : Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pl.read_csv(\"data/ratings.csv\")\n",
    "print(ratings_df.head(3))\n",
    "print(ratings_df.describe())\n",
    "# 1.14978e6 rows\n",
    "\n",
    "# Ratings exploration\n",
    "print(ratings_df.head(5))\n",
    "print(ratings_df.columns)\n",
    "print(ratings_df.dtypes)\n",
    "print(ratings_df.null_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ratings_data(df):\n",
    "    df = df.rename({\"User-ID\": \"user_id\", \"ISBN\": \"isbn\", \"Book-Rating\": \"rating\"})\n",
    "\n",
    "    # Filter out invalid ratings\n",
    "    df = df.filter((pl.col(\"rating\") >= 1) & (pl.col(\"rating\") <= 10))\n",
    "\n",
    "    # convert rating to float\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"rating\").cast(pl.Float32),\n",
    "        pl.col(\"user_id\").cast(pl.Utf8)\n",
    "    ])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ratings_df = clean_ratings_data(ratings_df)\n",
    "print(cleaned_ratings_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate histogram of ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "cleaned_ratings_df.select(\"rating\").to_pandas().hist(bins=10)\n",
    "plt.title(\"Distribution of Book Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create feature sets for two-tower model\n",
    "# def create_model_features(books_df, users_df, ratings_df, user_stats, book_stats):\n",
    "#     # Merge books with book stats\n",
    "#     book_features = books_df.join(book_stats, on=\"ISBN\", how=\"left\")\n",
    "    \n",
    "#     # Fill missing stats\n",
    "#     book_features = book_features.with_columns([\n",
    "#         pl.col(\"n_ratings\").fill_null(0),\n",
    "#         pl.col(\"avg_book_rating\").fill_null(0),\n",
    "#         pl.col(\"std_book_rating\").fill_null(0)\n",
    "#     ])\n",
    "    \n",
    "#     # Merge users with user stats\n",
    "#     user_features = users_df.join(user_stats, on=\"User-ID\", how=\"left\")\n",
    "    \n",
    "#     # Fill missing stats\n",
    "#     user_features = user_features.with_columns([\n",
    "#         pl.col(\"rating_count\").fill_null(0),\n",
    "#         pl.col(\"avg_rating\").fill_null(0),\n",
    "#         pl.col(\"std_rating\").fill_null(0),\n",
    "#         pl.col(\"min_rating\").fill_null(0),\n",
    "#         pl.col(\"max_rating\").fill_null(0)\n",
    "#     ])\n",
    "    \n",
    "#     # Prepare interaction data\n",
    "#     interactions = ratings_df.select([\n",
    "#         \"User-ID\", \n",
    "#         \"ISBN\", \n",
    "#         \"Book-Rating\"\n",
    "#     ])\n",
    "    \n",
    "#     # Create a binary label for implicit feedback\n",
    "#     interactions = interactions.with_columns([\n",
    "#         pl.when(pl.col(\"Book-Rating\") > 5)\n",
    "#         .then(1)\n",
    "#         .otherwise(0)\n",
    "#         .alias(\"positive_interaction\")\n",
    "#     ])\n",
    "    \n",
    "#     return book_features, user_features, interactions\n",
    "\n",
    "# book_features, user_features, interactions = create_model_features(\n",
    "#     cleaned_books_df, \n",
    "#     cleaned_users_df, \n",
    "#     processed_ratings_df, \n",
    "#     user_stats, \n",
    "#     book_stats\n",
    "# )\n",
    "\n",
    "# print(\"Book Features Sample:\")\n",
    "# print(book_features.head())\n",
    "# print(f\"Book Features Shape: {len(book_features)} rows, {len(book_features.columns)} columns\")\n",
    "\n",
    "# print(\"\\nUser Features Sample:\")\n",
    "# print(user_features.head())\n",
    "# print(f\"User Features Shape: {len(user_features)} rows, {len(user_features.columns)} columns\")\n",
    "\n",
    "# print(\"\\nInteractions Sample:\")\n",
    "# print(interactions.head())\n",
    "# print(f\"Interactions Shape: {len(interactions)} rows, {len(interactions.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Feature Groups for raw, cleaned-up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys import hopsworks_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project, fs = hopsworks_integration.feature_store.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = \"Customers data after cleaning and imputation\"\n",
    "users_fg = fs.get_or_create_feature_group(\n",
    "    name=\"users\",\n",
    "    description=\"Book customers data after cleaning and imputation\",\n",
    "    version=1,\n",
    "    primary_key=[\"user_id\"],\n",
    "    online_enabled=True,\n",
    ")\n",
    "users_fg.insert(cleaned_users_df, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create books fg\n",
    "desc = \"Books data after cleaning and imputation\"\n",
    "items_fg = fs.get_or_create_feature_group(\n",
    "    name=\"items\",\n",
    "    description=\"Books data after cleaning and imputation\",\n",
    "    version=1,\n",
    "    primary_key=[\"isbn\"],\n",
    "    online_enabled=True,\n",
    ")\n",
    "items_fg.insert(clean_books_df, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ratings fg\n",
    "desc = \"Ratings data after cleaning\"\n",
    "ratings_fg = fs.get_or_create_feature_group(\n",
    "    name=\"ratings\",\n",
    "    description=\"Ratings data after cleaning and imputation\",\n",
    "    version=1,\n",
    "    primary_key=[\"user_id\", \"isbn\"],\n",
    "    online_enabled=True,\n",
    ")\n",
    "ratings_fg.insert(cleaned_ratings_df, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
