{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "\n",
    "from recsys import hopsworks_integration\n",
    "from recsys.config import settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project, fs = hopsworks_integration.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Ranking Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.transformer import Transformer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HopsworksRankingModel:\n",
    "    deployment_name = \"ranking\"\n",
    "\n",
    "    def __init__(self, model) -> None:\n",
    "        self._model = model\n",
    "\n",
    "    @classmethod\n",
    "    def deploy(cls, project):\n",
    "        mr = project.get_model_registry()\n",
    "        dataset_api = project.get_dataset_api()\n",
    "\n",
    "        models = mr.get_models(name=\"cb_ranking_model\")\n",
    "        if len(models) == 0:\n",
    "            raise RuntimeError(\n",
    "                \"No 'candidate_model' found in Hopsworks model registry.\"\n",
    "            )\n",
    "        model = max(models, key=lambda m: m.version)\n",
    "\n",
    "        # Copy transformer file into Hopsworks File System\n",
    "        uploaded_file_path = dataset_api.upload(\n",
    "            str(\n",
    "                settings.RECSYS_DIR / \"inference\" / \"ranking_transformer.py\"\n",
    "            ),  # File name to be uploaded\n",
    "            \"Resources\",  # Destination directory in Hopsworks File System\n",
    "            overwrite=True,  # Overwrite the file if it already exists\n",
    "        )\n",
    "        # Construct the path to the uploaded transformer script\n",
    "        transformer_script_path = os.path.join(\n",
    "            \"/Projects\",  # Root directory for projects in Hopsworks\n",
    "            project.name,  # Name of the current project\n",
    "            uploaded_file_path,  # Path to the uploaded file within the project\n",
    "        )\n",
    "\n",
    "        ranking_transformer = Transformer(\n",
    "            script_file=transformer_script_path,\n",
    "            resources={\"num_instances\": 0},\n",
    "        )\n",
    "\n",
    "        # Upload predictor file to Hopsworks\n",
    "        uploaded_file_path = dataset_api.upload(\n",
    "            str(settings.RECSYS_DIR / \"inference\" / \"ranking_predictor.py\"),\n",
    "            \"Resources\",\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "        # Construct the path to the uploaded script\n",
    "        predictor_script_path = os.path.join(\n",
    "            \"/Projects\",\n",
    "            project.name,\n",
    "            uploaded_file_path,\n",
    "        )\n",
    "\n",
    "        # Deploy ranking model\n",
    "        ranking_deployment = model.deploy(\n",
    "            name=cls.deployment_name,\n",
    "            description=\"Deployment that search for item candidates and scores them based on customer query\",\n",
    "            resources={\"num_instances\": 0},\n",
    "            script_file=predictor_script_path,\n",
    "            transformer=ranking_transformer,\n",
    "        )\n",
    "\n",
    "        return ranking_deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_deployment = HopsworksRankingModel.deploy(\n",
    "    project=project\n",
    ")\n",
    "ranking_deployment.start(await_running=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(ranked_candidates, k=3):\n",
    "    return [candidate[-1] for candidate in ranked_candidates[\"ranking\"][:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ranking_input = [\n",
    "        {\n",
    "            # \"user_id\": \"256843\",\n",
    "            \"customer_id\": \"256843\",\n",
    "            \"query_emb\":[1.0040990114212036, 0.02099212259054184, 0.6753973364830017, \n",
    "                         -1.018194556236267, 1.0765583515167236, 0.8201298117637634, \n",
    "                         0.1209947019815445, 0.5214401483535767, -1.350378394126892, \n",
    "                         -0.1466677188873291, -0.19946162402629852, -0.004622574429959059, \n",
    "                         -0.9494196176528931, -0.16883370280265808, -0.3382653594017029, \n",
    "                         1.305509328842163\n",
    "                         ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Test ranking deployment\n",
    "ranked_candidates = ranking_deployment.predict(inputs=test_ranking_input)\n",
    "\n",
    "# Retrieve article ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{ranked_candidates=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_deployment.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_fg = fs.get_feature_group(name=\"items\", version=1)\n",
    "\n",
    "# get books feature view\n",
    "items_fv = fs.get_or_create_feature_view(\n",
    "    version=1,\n",
    "    name=\"items\",\n",
    "    description=\"Books feature view\",\n",
    "    query=items_fg.select_all()\n",
    ")\n",
    "\n",
    "recommendations_df = items_fv.get_feature_vectors([{\"isbn\": x} for x in recommendations], \n",
    "                                                  return_type=\"pandas\")\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "image_urls = recommendations_df[\"image_url_l\"].to_list()\n",
    "grid_html = '<div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 10px; max-width: 900px;\">'\n",
    "\n",
    "for url in image_urls:\n",
    "    grid_html += f'<img src=\"{url}\" style=\"width: 100%; height: auto;\">'\n",
    "\n",
    "grid_html += \"</div>\"\n",
    "\n",
    "display(HTML(grid_html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class Transformer(object):\n",
    "    def __init__(self):\n",
    "        # Connect to Hopsworks\n",
    "        project = hopsworks.login()\n",
    "        self.fs = project.get_feature_store()\n",
    "\n",
    "        # todo: get from rating feature view, but pop the ratings\n",
    "        self.rating_features = [\"user_id\", \"isbn\", \"age\", \"year_of_publication\"]\n",
    "\n",
    "        # Retrieve the 'candidate_embeddings' feature view\n",
    "        self.candidate_index = self.fs.get_feature_view(\n",
    "            version=1,\n",
    "            name=\"candidate_embeddings\",\n",
    "        )\n",
    "\n",
    "        # Retrieve the 'ratings' feature group\n",
    "        self.ratings_fg = self.fs.get_feature_group(\n",
    "            version=1,\n",
    "            name=\"ratings\",\n",
    "        )\n",
    "\n",
    "        self.items_fg = self.fs.get_feature_group(name=\"items\", version=1)\n",
    "        self.users_fg = self.fs.get_feature_group(name=\"users\", version=1)\n",
    "\n",
    "        self.users_fv = self.fs.get_or_create_feature_view(\n",
    "            version=1,\n",
    "            name=\"users\",\n",
    "            query=self.users_fg.select_all(),\n",
    "            description=\"users_feature_view\",\n",
    "        )\n",
    "\n",
    "    def preprocess(self, inputs):\n",
    "\n",
    "        # Extract the input instance\n",
    "        inputs = inputs[\"instances\"][0]\n",
    "\n",
    "        # Extract customer_id from inputs\n",
    "        user_id = inputs[\"user_id\"]\n",
    "\n",
    "        # Search for neighbors in the candidate index\n",
    "        neighbors = self.candidate_index.find_neighbors(\n",
    "            inputs[\"query_emb\"],\n",
    "            k=100,\n",
    "        )\n",
    "        neighbors = [neighbor[0].decode('utf-8') for neighbor in neighbors]\n",
    "\n",
    "        # Get IDs of items already bought by the customer\n",
    "        already_bought_items_ids = (\n",
    "            self.ratings_fg.select(\"isbn\")\n",
    "            .filter(self.ratings_fg.user_id==user_id)\n",
    "            .read(dataframe_type=\"pandas\").values.reshape(-1)\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        # Filter candidate items to exclude those already bought by the customer\n",
    "        item_id_list = [\n",
    "            str(item_id)\n",
    "            for item_id in neighbors\n",
    "            if str(item_id) not in already_bought_items_ids\n",
    "        ]\n",
    "\n",
    "        # Get item features for the candidate items\n",
    "        ranking_model_inputs_df = (\n",
    "            self.items_fg.select_all()\n",
    "            .filter(self.items_fg.isbn.isin(item_id_list))\n",
    "            .read(dataframe_type=\"pandas\")\n",
    "        )\n",
    "\n",
    "        logging.info(\"✅ Articles Data Retrieved!\")\n",
    "\n",
    "        # Add customer features\n",
    "        user_features = self.users_fv.get_feature_vector(\n",
    "                {\"user_id\": user_id},\n",
    "                return_type=\"pandas\",\n",
    "            )\n",
    "        \n",
    "        ranking_model_inputs_df[\"user_id\"] = user_id\n",
    "        ranking_model_inputs_df = ranking_model_inputs_df.merge(\n",
    "                                    user_features, \n",
    "                                    on=\"user_id\",\n",
    "                                    how=\"inner\")\n",
    "        \n",
    "        ranking_model_inputs_df = ranking_model_inputs_df[self.rating_features]\n",
    "\n",
    "        logging.info(\"✅ Inputs are ready!\")\n",
    "\n",
    "        return {\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"ranking_features\": ranking_model_inputs_df.values.tolist(),\n",
    "                    \"item_ids\": item_id_list,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def postprocess(self, outputs):\n",
    "        logging.info(\"✅ Predictions are ready!\")\n",
    "\n",
    "        # Merge prediction scores and corresponding article IDs into a list of tuples\n",
    "        ranking = list(zip(outputs[\"scores\"], outputs[\"item_ids\"]))\n",
    "\n",
    "        # Sort the ranking list by score in descending order\n",
    "        ranking.sort(reverse=True)\n",
    "\n",
    "        # Return the sorted ranking list\n",
    "        return {\n",
    "            \"ranking\": ranking,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the transformer\n",
    "# test_ranking_input = [\n",
    "#         {\n",
    "#             \"user_id\": \"256843\",\n",
    "#             \"query_emb\":[1.0040990114212036, 0.02099212259054184, 0.6753973364830017, \n",
    "#                          -1.018194556236267, 1.0765583515167236, 0.8201298117637634, \n",
    "#                          0.1209947019815445, 0.5214401483535767, -1.350378394126892, \n",
    "#                          -0.1466677188873291, -0.19946162402629852, -0.004622574429959059, \n",
    "#                          -0.9494196176528931, -0.16883370280265808, -0.3382653594017029, \n",
    "#                          1.305509328842163\n",
    "#                          ],\n",
    "#         }\n",
    "#     ]\n",
    "# inputs = {\"instances\": test_ranking_input}\n",
    "\n",
    "# transformer = Transformer()\n",
    "# preprocessed_inputs = transformer.preprocess(inputs)\n",
    "# preprocessed_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "class Predict(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        # self.model = load(os.environ[\"MODEL_FILES_PATH\"] + \"/ranking_model.pkl\")\n",
    "        self.model = CatBoostRegressor()\n",
    "        self.model.load_model(\"./ranking_model/model.cbm\") # os.environ[\"MODEL_FILES_PATH\"] + \n",
    "    \n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \n",
    "        logging.info(f\"✅ Inputs: {inputs}\")\n",
    "        \n",
    "        # Extract ranking features and article IDs from the inputs\n",
    "        features = inputs[0].pop(\"ranking_features\")\n",
    "        item_ids = inputs[0].pop(\"item_ids\")\n",
    "\n",
    "        # Make predictions\n",
    "        scores = self.model.predict(features).tolist()\n",
    "\n",
    "        return {\"item_ids\": item_ids, \"scores\": scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the predictor\n",
    "# predictor = Predict()\n",
    "# outputs = predictor.predict(preprocessed_inputs[\"inputs\"])\n",
    "\n",
    "# ranking = list(zip(outputs[\"scores\"], outputs[\"item_ids\"]))\n",
    "\n",
    "# # Sort the ranking list by score in descending order\n",
    "# ranking.sort(reverse=True)\n",
    "# ranking[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Query Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.transformer import Transformer\n",
    "\n",
    "class HopsworksQueryModel:\n",
    "    deployment_name = \"query\"\n",
    "\n",
    "    def __init__(self, model) -> None:\n",
    "        self.model = model\n",
    "\n",
    "    @classmethod\n",
    "    def deploy(cls, ranking_model_type: Literal[\"ranking\", \"llmranking\"] = \"ranking\"):\n",
    "        project = hopsworks.login()\n",
    "        \n",
    "        # Prepare secrets (the ranking deployment name) used in the deployment\n",
    "        cls._prepare_secrets(ranking_model_type)\n",
    "\n",
    "        mr = project.get_model_registry()\n",
    "        dataset_api = project.get_dataset_api()\n",
    "\n",
    "        # Retrieve the 'query_model' from the Model Registry\n",
    "        query_model = mr.get_model(\n",
    "            name=\"query_model\",\n",
    "            version=1,\n",
    "        )\n",
    "\n",
    "        # Upload input-Transformer script\n",
    "        #   Copy transformer file into Hopsworks File System\n",
    "        uploaded_file_path = dataset_api.upload(\n",
    "            str(settings.RECSYS_DIR / \"inference\" / \"query_transformer.py\"),\n",
    "            \"Models\",\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "        #   Construct the path to the uploaded script\n",
    "        transformer_script_path = os.path.join(\n",
    "            \"/Projects\",\n",
    "            project.name,\n",
    "            uploaded_file_path,\n",
    "        )\n",
    "\n",
    "        query_model_transformer = Transformer(\n",
    "            script_file=transformer_script_path,\n",
    "            resources={\"num_instances\": 0},\n",
    "        )\n",
    "\n",
    "        # Deploy the query model\n",
    "        query_model_deployment = query_model.deploy(\n",
    "            name=cls.deployment_name,\n",
    "            description=\"Generates query embeddings from customer and further push it through the ranking deployment\",\n",
    "            resources={\"num_instances\": 0},\n",
    "            transformer=query_model_transformer,\n",
    "        )\n",
    "\n",
    "        return query_model_deployment\n",
    "\n",
    "    @classmethod\n",
    "    def _prepare_secrets(cls, ranking_model_type: Literal[\"ranking\", \"llmranking\"]):\n",
    "        project = hopsworks.login(\n",
    "            hostname_verification=False,\n",
    "            api_key_value=settings.HOPSWORKS_API_KEY.get_secret_value(),     \n",
    "        )\n",
    "        secrets_api = hopsworks.get_secrets_api()\n",
    "        secrets = secrets_api.get_secrets()\n",
    "\n",
    "        # delete existing RANKING_MODEL_TYPE\n",
    "        existing_secret_keys = [secret.name for secret in secrets]\n",
    "        if \"RANKING_MODEL_TYPE\" in existing_secret_keys:\n",
    "            secrets_api._delete(name=\"RANKING_MODEL_TYPE\")\n",
    "\n",
    "        # create new RANKING_MODEL_TYPE\n",
    "        secrets_api.create_secret(\n",
    "            \"RANKING_MODEL_TYPE\",\n",
    "            ranking_model_type,\n",
    "            project=project.name,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_model_deployment = HopsworksQueryModel.deploy(ranking_model_type=\"ranking\")\n",
    "query_model_deployment.start(await_running=180) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_input = [\n",
    "        {\n",
    "            \"user_id\": \"251843\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "ranked_candidates = query_model_deployment.predict(inputs=test_query_input)\n",
    "print(f\"Query embeddings: {ranked_candidates['predictions']}\")\n",
    "\n",
    "\n",
    "# # Retrieve article ids of the top recommended items\n",
    "# recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "# recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_model_deployment.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer():\n",
    "    def __init__(self) -> None:\n",
    "        # Connect to the Hopsworks\n",
    "        project = hopsworks.login()\n",
    "        fs = project.get_feature_store()\n",
    "\n",
    "        # Retrieve the deployed-ranking-model\n",
    "        ms = project.get_model_serving()\n",
    "        self._retrieve_secrets()\n",
    "        print(f\"{self.ranking_model_type=}\")\n",
    "        self.ranking_server = ms.get_deployment(self.ranking_model_type)\n",
    "\n",
    "        # Retrieve the 'customers' feature view\n",
    "        self.customer_fv = fs.get_feature_view(\n",
    "            version=1,\n",
    "            name=\"users\",\n",
    "        )\n",
    "\n",
    "        # # Retrieve  the \"ranking\" feature view and initialize the batch scoring server.\n",
    "        # self.ranking_fv = fs.get_feature_view(name=\"ranking\", version=1)\n",
    "        # self.ranking_fv.init_batch_scoring(1)\n",
    "\n",
    "\n",
    "    def _retrieve_secrets(self):\n",
    "        project = hopsworks.login()\n",
    "        secrets_api = hopsworks.get_secrets_api()\n",
    "        try:\n",
    "            self.ranking_model_type = secrets_api.get_secret(\"RANKING_MODEL_TYPE\").value\n",
    "        except Exception as e:\n",
    "            logging.error(e)\n",
    "            logging.error(\"Could not retrieve secret RANKING_MODEL_TYPE, defaulting to ranker\")\n",
    "            self.ranking_model_type = \"ranking\"  \n",
    "\n",
    "    def preprocess(self, inputs):\n",
    "        # Check if the input data contains a key named \"instances\"\n",
    "        # and extract the actual data if present\n",
    "        inputs = inputs[\"instances\"] if \"instances\" in inputs else inputs\n",
    "        inputs = inputs[0]      \n",
    "\n",
    "        # Extract customer_id and transaction_date from the inputs\n",
    "        user_id = inputs[\"user_id\"]\n",
    "        # transaction_date = inputs[\"transaction_date\"]\n",
    "\n",
    "        # # Extract month from the transaction_date\n",
    "        # month_of_purchase = datetime.fromisoformat(inputs.pop(\"transaction_date\"))\n",
    "\n",
    "        # Get customer features\n",
    "        customer_features = self.customer_fv.get_feature_vector(\n",
    "            {\"user_id\": user_id},\n",
    "            return_type=\"pandas\",\n",
    "        )\n",
    "\n",
    "        # Enrich inputs with customer age\n",
    "        # todo: add other features!!\n",
    "        inputs[\"age\"] = customer_features.age.values[0]\n",
    "\n",
    "        # # on-demand transformation\n",
    "        # # on-demand transformation\n",
    "        # # on-demand transformation\n",
    "        # # Calculate the sine and cosine of the month_of_purchase\n",
    "        # month_of_purchase = datetime.strptime(\n",
    "        #     transaction_date, \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "        # ).month\n",
    "\n",
    "        # # Calculate the sine and cosine components for the month_of_purchase using on-demand transformation present in \"ranking\" feature view.\n",
    "        # feature_vector = self.ranking_fv._batch_scoring_server.compute_on_demand_features(\n",
    "        #     feature_vectors=pd.DataFrame([inputs]), request_parameters={\"month\": month_of_purchase}\n",
    "        # ).to_dict(orient=\"records\")[0]\n",
    "\n",
    "        # inputs[\"month_sin\"] = feature_vector[\"month_sin\"]\n",
    "        # inputs[\"month_cos\"] = feature_vector[\"month_cos\"]\n",
    "\n",
    "        return {\"instances\": [inputs]}\n",
    "\n",
    "    def postprocess(self, outputs):\n",
    "        # Return ordered ranking predictions\n",
    "        return self.ranking_server.predict(inputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = Transformer()\n",
    "# preprocessed_inputs = transformer.preprocess(test_query_input)\n",
    "# preprocessed_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_deployment.stop()\n",
    "query_model_deployment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
